# üöÄ Utiliser Sora avec Azure (Azure AI Foundry)

## üìò Vue d'ensemble

Ce projet utilise le mod√®le **Sora** via **Azure AI Foundry** pour g√©n√©rer des vid√©os de 1 seconde √† partir d'une **image et d'un prompt textuel**.

‚úÖ **Fonctionnalit√© image-to-video** : Sora sur Azure AI Foundry supporte la g√©n√©ration de vid√©os √† partir d'images via le param√®tre `inpaint_items` avec upload multipart/form-data.

---

## üîë Configuration Azure

### Variables d'environnement

Les variables sont d√©j√† configur√©es dans `.env.local` :

```bash
AZURE_API_KEY=your_azure_api_key_here
AZURE_SORA_ENDPOINT=https://your-deployment.openai.azure.com/openai/v1/video/generations/jobs?api-version=preview
```

### Point de terminaison

L'API Sora est accessible √† :
```
https://bapti-m70vyuu5-eastus2.openai.azure.com/openai/v1/video/generations/jobs?api-version=preview
```

---

## üé¨ Comment √ßa fonctionne

### 1. Cr√©ation du job de g√©n√©ration (Image-to-Video)

L'application envoie une requ√™te POST en **multipart/form-data** avec :
- `model`: "sora"
- `prompt`: Description de l'animation souhait√©e
- `height`: 1080
- `width`: 1080
- `n_seconds`: 1
- `n_variants`: 1
- `inpaint_items`: Configuration de l'image de d√©part (JSON stringifi√©)
- `files`: Le fichier image lui-m√™me

**Structure de `inpaint_items`** :
```json
[
  {
    "frame_index": 0,
    "type": "image",
    "file_name": "input.jpg",
    "crop_bounds": {
      "left_fraction": 0.0,
      "top_fraction": 0.0,
      "right_fraction": 1.0,
      "bottom_fraction": 1.0
    }
  }
]
```

**Note importante** : L'image est envoy√©e directement √† Sora qui l'utilise comme point de d√©part pour g√©n√©rer la vid√©o anim√©e.

### 2. Polling du statut

L'application v√©rifie r√©guli√®rement (toutes les 2 secondes) le statut du job jusqu'√† ce qu'il soit termin√©.

### 3. R√©cup√©ration de la vid√©o

Une fois le job termin√©, l'URL de la vid√©o g√©n√©r√©e est r√©cup√©r√©e et t√©l√©charg√©e.

---

## üì¶ Param√®tres Sora

| Param√®tre | Type | Description | Valeur par d√©faut |
|-----------|------|-------------|-------------------|
| `model` | string | Nom du mod√®le | `"sora"` |
| `prompt` | string | Description de la vid√©o √† g√©n√©rer | - |
| `height` | integer | Hauteur en pixels | `1080` |
| `width` | integer | Largeur en pixels | `1080` |
| `n_seconds` | integer | Dur√©e de la vid√©o | `1` |
| `n_variants` | integer | Nombre de variantes | `1` |

---

## ‚öôÔ∏è D√©tails du d√©ploiement

| Champ | Valeur |
|-------|--------|
| Nom du mod√®le | sora |
| Version | 2025-05-02 |
| Type de d√©ploiement | Standard global |
| Limite de d√©bit | 60 requ√™tes/min, 60 000 tokens/min |
| Statut | Preview |
| Date de mise hors service | 15 f√©vrier 2026 |

---

## üíª Impl√©mentation dans le projet

### Fichier `lib/sora.ts`

Ce fichier contient les fonctions pour :
- Cr√©er un job de g√©n√©ration vid√©o
- Effectuer le polling du statut
- R√©cup√©rer l'URL de la vid√©o g√©n√©r√©e

### Fichier `app/api/generate/route.ts`

Cette API route :
1. Upload l'image dans Supabase (`input-images`)
2. R√©cup√®re l'URL publique de l'image
3. Appelle Sora avec l'URL de l'image et le prompt
4. T√©l√©charge la vid√©o g√©n√©r√©e
5. Upload la vid√©o dans Supabase (`output-videos`)
6. Sauvegarde les informations dans la base de donn√©es

---

## üîç Exemple d'utilisation

### Depuis l'interface web

1. Uploadez une image
2. Entrez un prompt comme :
   - "Make this image come to life with subtle movement"
   - "Add a gentle animation to this scene"
   - "Create a short video loop from this image"
3. Cliquez sur "G√©n√©rer la vid√©o"
4. Attendez 1-2 minutes
5. La vid√©o de 1 seconde s'affiche automatiquement

### Appel API direct (curl)

```bash
curl -X POST "https://bapti-m70vyuu5-eastus2.openai.azure.com/openai/v1/video/generations/jobs?api-version=preview" \
  -H "Content-Type: application/json" \
  -H "Api-key: $AZURE_API_KEY" \
  -d '{
    "model": "sora",
    "prompt": "Based on this image: [URL]. Make it come to life",
    "height": 1080,
    "width": 1080,
    "n_seconds": 1,
    "n_variants": 1
  }'
```

---

## üêõ D√©pannage

### Erreur "Job timeout"
- Augmentez le `maxAttempts` dans `lib/sora.ts` (actuellement 60 tentatives = 2 minutes)

### Erreur "Invalid API key"
- V√©rifiez que `AZURE_API_KEY` dans `.env.local` est correct

### Erreur "Endpoint not found"
- V√©rifiez que `AZURE_SORA_ENDPOINT` est correct
- Le mod√®le Sora doit √™tre d√©ploy√© dans votre projet Azure

### La vid√©o ne se g√©n√®re pas
- V√©rifiez les logs du serveur (`npm run dev`)
- V√©rifiez que le bucket `output-videos` existe et est public
- V√©rifiez que vous n'avez pas d√©pass√© la limite de 60 requ√™tes/min

---

## üîó Ressources

- [Documentation Azure AI Foundry](https://learn.microsoft.com/azure/ai-foundry)
- [Dashboard Azure](https://portal.azure.com)
- [Endpoint REST](https://bapti-m70vyuu5-eastus2.openai.azure.com)

---

## üß† Conseil

Sora est actuellement en **Preview**, donc certaines fonctionnalit√©s peuvent √©voluer.
Surveillez la documentation officielle Azure pour les changements d'API et de quotas.

**Date de fin de preview** : 15 f√©vrier 2026

---

## ‚ö†Ô∏è Limitations importantes

### üö´ Sora Azure limitations :
- **Dur√©es longues** : Limit√© √† quelques secondes (1-10s recommand√© en Preview)
- **R√©solution maximale** : Varie selon le format choisi
- **Quota** : 60 requ√™tes/min, 60 000 tokens/min

### ‚úÖ Sora Azure supporte :
- **Image-to-video** : ‚úÖ G√©n√©ration √† partir d'une image de base (via `inpaint_items`)
- **Text-to-video** : ‚úÖ G√©n√©ration √† partir de descriptions textuelles uniquement
- **Video-to-video** : ‚úÖ Modification de vid√©os existantes (via `inpaint_items` avec type "video")
- **Prompts riches** : Plus le prompt est descriptif et pr√©cis, meilleur est le r√©sultat
- **R√©solutions variables** : Diff√©rents formats (carr√©, paysage, portrait)
- **Multiples variantes** : G√©n√©ration de plusieurs versions d'une m√™me vid√©o

### üîÑ Workflow actuel de l'application

1. **Upload image** : L'utilisateur upload une image (stock√©e dans Supabase)
2. **Prompt textuel** : L'utilisateur d√©crit l'animation/transformation souhait√©e
3. **G√©n√©ration Sora** : Sora g√©n√®re une vid√©o bas√©e sur **l'image ET le prompt**
   - L'image est envoy√©e via `multipart/form-data`
   - Configuration via `inpaint_items` pour placer l'image au frame 0
   - Le prompt guide l'animation/transformation
4. **T√©l√©chargement** : La vid√©o g√©n√©r√©e est t√©l√©charg√©e depuis Azure
5. **Stockage** : La vid√©o est stock√©e dans Supabase (bucket `output-videos`)
6. **Affichage** : La vid√©o est affich√©e √† l'utilisateur

**Exemple de workflow concret** :
- Image : Photo d'un paysage statique
- Prompt : "Add gentle camera movement, animate the clouds, add subtle wind effects"
- R√©sultat : Vid√©o de 1 seconde du paysage avec les animations demand√©es
