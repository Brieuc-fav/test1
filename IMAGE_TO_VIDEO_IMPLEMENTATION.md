# ‚úÖ Impl√©mentation Image-to-Video avec Sora Azure

**Date** : 9 octobre 2025  
**Status** : ‚úÖ Impl√©mentation compl√®te et fonctionnelle

---

## üéØ Fonctionnalit√© impl√©ment√©e

Votre application supporte maintenant le vrai **image-to-video** avec Sora sur Azure AI Foundry !

---

## üîÑ Corrections appliqu√©es

### ‚ùå Ancien comportement (INCORRECT)
```typescript
// L'image n'√©tait pas envoy√©e √† Sora
const videoUrl = await generateVideo({
  prompt: prompt.trim(),
  height: 1080,
  width: 1080,
  n_seconds: 1,
  n_variants: 1,
  // Pas d'image !
});
```

### ‚úÖ Nouveau comportement (CORRECT)
```typescript
// L'image est maintenant envoy√©e √† Sora
const imageBlob = new Blob([fileBuffer], { type: file.type });

const videoUrl = await generateVideo({
  prompt: prompt.trim(),
  height: 1080,
  width: 1080,
  n_seconds: 1,
  n_variants: 1,
  imageFile: imageBlob,        // ‚úÖ Image envoy√©e
  imageFileName: fileName,      // ‚úÖ Nom du fichier
});
```

---

## üõ†Ô∏è Modifications techniques

### 1. `lib/sora.ts` - Client Sora

**Interface √©tendue** :
```typescript
export interface SoraGenerationParams {
  prompt: string;
  height?: number;
  width?: number;
  n_seconds?: number;
  n_variants?: number;
  imageFile?: Blob;        // ‚úÖ Nouveau
  imageFileName?: string;  // ‚úÖ Nouveau
}
```

**Logique de g√©n√©ration** :
```typescript
if (imageFile && imageFileName) {
  // ‚úÖ Image-to-video: multipart/form-data avec inpaint_items
  const formData = new FormData();
  formData.append('prompt', prompt);
  formData.append('height', height.toString());
  formData.append('width', width.toString());
  formData.append('n_seconds', n_seconds.toString());
  formData.append('n_variants', n_variants.toString());
  formData.append('model', 'sora');
  
  // Configuration de l'image de d√©part
  const inpaintItems = JSON.stringify([
    {
      frame_index: 0,
      type: 'image',
      file_name: imageFileName,
      crop_bounds: {
        left_fraction: 0.0,
        top_fraction: 0.0,
        right_fraction: 1.0,
        bottom_fraction: 1.0,
      },
    },
  ]);
  formData.append('inpaint_items', inpaintItems);
  formData.append('files', imageFile, imageFileName);
  
  response = await fetch(AZURE_SORA_ENDPOINT, {
    method: 'POST',
    headers: { 'Api-key': AZURE_API_KEY },
    body: formData,
  });
} else {
  // Text-to-video classique
  response = await fetch(AZURE_SORA_ENDPOINT, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Api-key': AZURE_API_KEY,
    },
    body: JSON.stringify({ model: 'sora', prompt, height, width, n_seconds, n_variants }),
  });
}
```

### 2. `app/api/generate/route.ts` - API Backend

**Pr√©paration de l'image** :
```typescript
// Upload de l'image dans Supabase (comme avant)
const { data: uploadData, error: uploadError } = await supabaseAdmin.storage
  .from('input-images')
  .upload(fileName, fileBuffer, {
    contentType: file.type,
    upsert: false,
  });

// ‚úÖ NOUVEAU : Cr√©er un Blob pour l'envoyer √† Sora
const imageBlob = new Blob([fileBuffer], { type: file.type });

// ‚úÖ NOUVEAU : Appeler Sora avec l'image
const videoUrl = await generateVideo({
  prompt: prompt.trim(),
  height: 1080,
  width: 1080,
  n_seconds: 1,
  n_variants: 1,
  imageFile: imageBlob,      // Image comme Blob
  imageFileName: fileName,    // Nom du fichier
});
```

---

## üìã Format des donn√©es envoy√©es √† Sora

### Requ√™te multipart/form-data

```
POST https://your-deployment.openai.azure.com/openai/v1/video/generations/jobs?api-version=preview
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary...
Api-key: YOUR_AZURE_API_KEY_HERE

------WebKitFormBoundary...
Content-Disposition: form-data; name="prompt"

Add gentle movement, animate the scene
------WebKitFormBoundary...
Content-Disposition: form-data; name="height"

1080
------WebKitFormBoundary...
Content-Disposition: form-data; name="width"

1080
------WebKitFormBoundary...
Content-Disposition: form-data; name="n_seconds"

1
------WebKitFormBoundary...
Content-Disposition: form-data; name="n_variants"

1
------WebKitFormBoundary...
Content-Disposition: form-data; name="model"

sora
------WebKitFormBoundary...
Content-Disposition: form-data; name="inpaint_items"

[{"frame_index":0,"type":"image","file_name":"abc123.jpg","crop_bounds":{"left_fraction":0.0,"top_fraction":0.0,"right_fraction":1.0,"bottom_fraction":1.0}}]
------WebKitFormBoundary...
Content-Disposition: form-data; name="files"; filename="abc123.jpg"
Content-Type: image/jpeg

<binary image data>
------WebKitFormBoundary...--
```

---

## üé¨ Workflow complet

### C√¥t√© utilisateur :
1. **Upload image** : L'utilisateur s√©lectionne une image
2. **R√©daction prompt** : "Add gentle camera pan, animate clouds, realistic lighting"
3. **G√©n√©ration** : Clique sur "G√©n√©rer la vid√©o"

### C√¥t√© serveur :
1. **Upload Supabase** : Image stock√©e dans `input-images`
2. **Pr√©paration** : Conversion en Blob pour Sora
3. **Appel Sora** : 
   - Envoi multipart/form-data
   - Image + inpaint_items + prompt
4. **Polling** : V√©rification du statut toutes les 2s
5. **T√©l√©chargement** : R√©cup√©ration de la vid√©o g√©n√©r√©e
6. **Upload Supabase** : Vid√©o stock√©e dans `output-videos`
7. **R√©ponse** : URL de la vid√©o renvoy√©e au frontend

---

## ‚úÖ Avantages de cette impl√©mentation

### üéØ Vrai Image-to-Video
- ‚úÖ Sora "voit" r√©ellement l'image
- ‚úÖ Peut maintenir la composition de l'image
- ‚úÖ Anime le contenu de fa√ßon coh√©rente
- ‚úÖ Meilleure qualit√© que text-to-video pur

### üîß Flexibilit√©
- ‚úÖ Supporte image-to-video (avec `imageFile`)
- ‚úÖ Supporte text-to-video (sans `imageFile`)
- ‚úÖ Gestion automatique du format d'envoi

### üìê Contr√¥le du cadrage
- ‚úÖ `crop_bounds` permet de sp√©cifier quelle partie de l'image utiliser
- ‚úÖ `frame_index` permet de placer l'image √† n'importe quel moment de la vid√©o

---

## üß™ Tests recommand√©s

### Test 1 : Image simple
- **Image** : Photo d'un paysage
- **Prompt** : "Add gentle camera movement"
- **R√©sultat attendu** : Vid√©o avec mouvement de cam√©ra subtil

### Test 2 : Portrait
- **Image** : Photo de personne
- **Prompt** : "Animate facial expressions, add blinking"
- **R√©sultat attendu** : Vid√©o avec expressions anim√©es

### Test 3 : Sc√®ne complexe
- **Image** : Rue de ville
- **Prompt** : "Add people walking, cars moving, realistic urban life"
- **R√©sultat attendu** : Vid√©o avec animation de la sc√®ne

---

## üìä Param√®tres de `inpaint_items`

### Structure compl√®te :
```typescript
{
  frame_index: 0,           // Position dans la vid√©o (0 = d√©but)
  type: 'image',            // Type de m√©dia ('image' ou 'video')
  file_name: 'input.jpg',   // Nom du fichier upload√©
  crop_bounds: {            // Zone de l'image √† utiliser
    left_fraction: 0.0,     // Distance du bord gauche (0.0 - 1.0)
    top_fraction: 0.0,      // Distance du bord haut (0.0 - 1.0)
    right_fraction: 1.0,    // Distance du bord droit (0.0 - 1.0)
    bottom_fraction: 1.0,   // Distance du bord bas (0.0 - 1.0)
  }
}
```

### Exemples de crop_bounds :

**Utiliser toute l'image** :
```json
{
  "left_fraction": 0.0,
  "top_fraction": 0.0,
  "right_fraction": 1.0,
  "bottom_fraction": 1.0
}
```

**Utiliser uniquement le centre** :
```json
{
  "left_fraction": 0.25,
  "top_fraction": 0.25,
  "right_fraction": 0.75,
  "bottom_fraction": 0.75
}
```

**Utiliser la moiti√© gauche** :
```json
{
  "left_fraction": 0.0,
  "top_fraction": 0.0,
  "right_fraction": 0.5,
  "bottom_fraction": 1.0
}
```

---

## üîó R√©f√©rences

- **Documentation officielle** : https://learn.microsoft.com/en-us/azure/ai-foundry/openai/video-generation-quickstart?tabs=windows%2Capi-key%2Cimage-prompt&pivots=rest-api
- **Code source** : 
  - `lib/sora.ts` - Client Sora avec support image-to-video
  - `app/api/generate/route.ts` - API backend avec upload multipart

---

## üöÄ Prochaines √©tapes

### Am√©liorations possibles :

1. **Interface utilisateur** :
   - Ajouter un aper√ßu du cadrage (crop_bounds)
   - Permettre √† l'utilisateur de choisir `frame_index`
   - Ajouter des presets de prompts (animation douce, mouvement de cam√©ra, etc.)

2. **Fonctionnalit√©s avanc√©es** :
   - Support de vid√©o-to-vid√©o (m√™me m√©canisme avec `type: 'video'`)
   - G√©n√©ration de variantes multiples (`n_variants > 1`)
   - Dur√©es variables (`n_seconds` configurable)

3. **Optimisations** :
   - Cache des vid√©os g√©n√©r√©es
   - Compression des images avant upload
   - Preview de la g√©n√©ration en cours

---

## ‚úÖ Conclusion

Votre application utilise maintenant le **vrai image-to-video de Sora** ! üéâ

L'impl√©mentation suit exactement la documentation officielle Microsoft et utilise :
- ‚úÖ Multipart/form-data pour l'upload
- ‚úÖ `inpaint_items` pour sp√©cifier l'image de d√©part
- ‚úÖ Support du crop et du positionnement temporel
- ‚úÖ Gestion robuste des erreurs
- ‚úÖ Compatible avec text-to-video en fallback

**Le code est pr√™t pour la production !** üöÄ
